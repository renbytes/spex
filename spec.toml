# spec.toml
language = "pyspark"
analysis_type = "app engagement"
description = "Analyzes app_logs[D[D[D[D[D[D[D[D[D[D[D[D[D[D[D[D[D[Dda data for app engagement."

[[dataset]]
name = "app_logs[D[D[D[D[D[D[D[D[D[D[D[D[D[D[D[D[D[Dda"
description = "app engagement"
# Option 1: Point to your actual data file
# sample_data_path = "path/to/app_logs[D[D[D[D[D[D[D[D[D[D[D[D[D[D[D[D[D[Dda.csv"

# Option 2: Provide inline sample data (recommended for quick start)
sample_data_block = """
user_id,event_type,page_id,timestamp,session_id
user_001,impression,home_page,2025-01-15T10:00:00Z,session_123
user_001,click,home_page,2025-01-15T10:00:05Z,session_123
user_002,impression,product_page,2025-01-15T10:01:00Z,session_124
"""

# Define your expected output dataset(s)
[[output_dataset]]
name = "analysis_results"
description = "Summary results from app engagement analysis"
sample_data_block = """
metric_name,value,percentage
total_users,1000,100.0
active_users,750,75.0
converted_users,150,15.0
"""

# Define metrics to calculate (optional but recommended)
[[metric]]
name = "total_count"
logic = "Count all unique records"
aggregation = "Count"
aggregation_field = "id"

[[metric]]
name = "unique_users"
logic = "Count distinct users in the dataset"
aggregation = "CountDistinct"
aggregation_field = "user_id"